{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4807599-f56f-4d6c-87d8-069c3a006faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from bs4 import BeautifulSoup\n",
    "import feedparser\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc1b2d2f-0e95-4d81-9689-36766b542d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ff6f7d4a-7263-403e-9ab0-ea6d789ff69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../config.json\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a181f987-f7b6-4b01-a106-f9a51b276e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArxivRSS:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.papers = dict()\n",
    "\n",
    "    def fetch_paper_list(self):\n",
    "        feed = self._fetch_n_parse_rss()\n",
    "\n",
    "        for rss_entry in feed[\"entries\"]:\n",
    "            paper_information = self._extract_paper_information(rss_entry)\n",
    "            self.papers[paper_information[\"id\"]] = paper_information\n",
    "\n",
    "    def _fetch_n_parse_rss(self):\n",
    "        feed = feedparser.parse(self.url)\n",
    "        return feed\n",
    "\n",
    "    def _parse_html_element(self, raw_string):\n",
    "        soup = BeautifulSoup(raw_string, \"html.parser\")\n",
    "        return soup.text\n",
    "\n",
    "    def _extract_paper_information(self, rss_entry):\n",
    "        paper_id = rss_entry[\"id\"]\n",
    "        paper_title = rss_entry[\"title\"]\n",
    "        paper_abstract = self._parse_html_element(rss_entry[\"summary\"])\n",
    "        paper_url = rss_entry[\"link\"]\n",
    "        paper_authors = []\n",
    "        for author_info in rss_entry[\"authors\"]:\n",
    "            author_name = self._parse_html_element(author_info[\"name\"])\n",
    "            paper_authors.append(author_name)\n",
    "        return {\n",
    "            \"id\": paper_id,\n",
    "            \"title\": paper_title,\n",
    "            \"abstract\": paper_abstract.replace(\"\\n\", \" \"),\n",
    "            \"url\": paper_url,\n",
    "            \"authors\": paper_authors,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b97e29-f49b-402d-a28c-335e1d6597de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be594192-ffb9-41e7-aed7-33db3a004224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92110018-4bbe-4ebd-9bb7-fc6a8f4eeb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47f284c-ff27-46c7-a157-e8f3da7299cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5710f0c6-e495-4439-9290-670b10e9c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_url = config['arxiv_rss_base_url'] + config['arxiv_subjects'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adc460e9-4ebe-4447-8041-5d4c1965d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rss = ArxivRSS(rss_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db850766-aecd-4fdb-b8f3-902506763ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_list = rss.fetch_paper_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7bdbf03-287a-4499-9dac-b832136d72c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = list(rss.papers.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3f2909e-0b59-4834-8b2d-496cb4aa590c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This document serves as an overview of the different mechanisms and areas of governance in the BigCode project. It aims to support transparency by providing relevant information about choices that were made during the project to the broader public, and to serve as an example of intentional governance of an open research project that future endeavors can leverage to shape their own approach. The first section, Project Structure, covers the project organization, its stated goals and values, its internal decision processes, and its funding and resources. The second section, Data and Model Governance, covers decisions relating to the questions of data subject consent, privacy, and model release. \n"
     ]
    }
   ],
   "source": [
    "print(papers[4][\"abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe7c3d76-54cb-4ad1-89bd-beb1e8b7e24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://arxiv.org/rss/cs.CY'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rss_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe743dcf-e2d5-4ae4-9f9e-95fce0a77741",
   "metadata": {},
   "outputs": [],
   "source": [
    "feed = feedparser.parse(rss_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "499d47eb-3f2c-49e8-900d-79961d9b0a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'title_detail', 'links', 'link', 'subtitle', 'subtitle_detail', 'language', 'updated', 'updated_parsed', 'publisher', 'publisher_detail', 'tags', 'sy_updatebase', 'sy_updatefrequency', 'sy_updateperiod', 'rdf_li', 'rdf_seq', 'entries', 'image'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed.feed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3951a89-a2b6-41d5-b97d-4564485da1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bozo', 'entries', 'feed', 'headers', 'etag', 'updated', 'updated_parsed', 'href', 'status', 'encoding', 'version', 'namespaces'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3125d822-9fcf-4bf9-a72b-b7214a7452bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = feed.entries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be8b8644-86b2-4c6c-b4c9-2301c851e596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://arxiv.org/abs/2312.03749'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5edfdfaa-cd29-40bc-8c38-3be2f8430b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'http://arxiv.org/abs/2312.03749',\n",
       " 'title': 'Conceptual Engineering Using Large Language Models. (arXiv:2312.03749v1 [cs.CL])',\n",
       " 'title_detail': {'type': 'text/plain',\n",
       "  'language': None,\n",
       "  'base': 'http://export.arxiv.org/rss/cs.CY',\n",
       "  'value': 'Conceptual Engineering Using Large Language Models. (arXiv:2312.03749v1 [cs.CL])'},\n",
       " 'links': [{'rel': 'alternate',\n",
       "   'type': 'text/html',\n",
       "   'href': 'http://arxiv.org/abs/2312.03749'}],\n",
       " 'link': 'http://arxiv.org/abs/2312.03749',\n",
       " 'summary': \"<p>We describe a method, based on Jennifer Nado's definition of classification\\nprocedures as targets of conceptual engineering, that implements such\\nprocedures using a large language model. We then apply this method using data\\nfrom the Wikidata knowledge graph to evaluate concept definitions from two\\nparadigmatic conceptual engineering projects: the International Astronomical\\nUnion's redefinition of PLANET and Haslanger's ameliorative analysis of WOMAN.\\nWe discuss implications of this work for the theory and practice of conceptual\\nengineering. The code and data can be found on GitHub.\\n</p>\",\n",
       " 'summary_detail': {'type': 'text/html',\n",
       "  'language': None,\n",
       "  'base': 'http://export.arxiv.org/rss/cs.CY',\n",
       "  'value': \"<p>We describe a method, based on Jennifer Nado's definition of classification\\nprocedures as targets of conceptual engineering, that implements such\\nprocedures using a large language model. We then apply this method using data\\nfrom the Wikidata knowledge graph to evaluate concept definitions from two\\nparadigmatic conceptual engineering projects: the International Astronomical\\nUnion's redefinition of PLANET and Haslanger's ameliorative analysis of WOMAN.\\nWe discuss implications of this work for the theory and practice of conceptual\\nengineering. The code and data can be found on GitHub.\\n</p>\"},\n",
       " 'authors': [{'name': '<a href=\"http://arxiv.org/find/cs/1/au:+Allen_B/0/1/0/all/0/1\">Bradley P. Allen</a>'}],\n",
       " 'author': '<a href=\"http://arxiv.org/find/cs/1/au:+Allen_B/0/1/0/all/0/1\">Bradley P. Allen</a>',\n",
       " 'author_detail': {'name': '<a href=\"http://arxiv.org/find/cs/1/au:+Allen_B/0/1/0/all/0/1\">Bradley P. Allen</a>'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c3cbb48-6b4c-4ba9-81b3-5ee60c7f69a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Conceptual Engineering Using Large Language Models. (arXiv:2312.03749v1 [cs.CL])'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7ec617f-ddb6-42e7-974d-5c84d7b4792c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<p>We describe a method, based on Jennifer Nado's definition of classification\\nprocedures as targets of conceptual engineering, that implements such\\nprocedures using a large language model. We then apply this method using data\\nfrom the Wikidata knowledge graph to evaluate concept definitions from two\\nparadigmatic conceptual engineering projects: the International Astronomical\\nUnion's redefinition of PLANET and Haslanger's ameliorative analysis of WOMAN.\\nWe discuss implications of this work for the theory and practice of conceptual\\nengineering. The code and data can be found on GitHub.\\n</p>\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c915241-75f5-430e-999b-d7c985cebdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://arxiv.org/abs/2312.03749'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e132308-f0d4-475f-a943-47d2188eed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(paper['authors'][0]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5788f6a5-df5b-4a2d-9b15-929e3b4eaff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bradley P. Allen'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_html_element(paper['authors'][0]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3518488-430f-4f75-a577-ccdb567472ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_info = extract_paper_information(feed.entries[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de1d024b-e65c-4c54-9c82-f37c0f9e654f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'http://arxiv.org/abs/2312.03755',\n",
       " 'title': 'Near-real-time Earthquake-induced Fatality Estimation using Crowdsourced Data and Large-Language Models. (arXiv:2312.03755v1 [cs.CL])',\n",
       " 'abstract': \"When a damaging earthquake occurs, immediate information about casualties is\\ncritical for time-sensitive decision-making by emergency response and aid\\nagencies in the first hours and days. Systems such as Prompt Assessment of\\nGlobal Earthquakes for Response (PAGER) by the U.S. Geological Survey (USGS)\\nwere developed to provide a forecast within about 30 minutes of any significant\\nearthquake globally. Traditional systems for estimating human loss in disasters\\noften depend on manually collected early casualty reports from global media, a\\nprocess that's labor-intensive and slow with notable time delays. Recently,\\nsome systems have employed keyword matching and topic modeling to extract\\nrelevant information from social media. However, these methods struggle with\\nthe complex semantics in multilingual texts and the challenge of interpreting\\never-changing, often conflicting reports of death and injury numbers from\\nvarious unverified sources on social media platforms. In this work, we\\nintroduce an end-to-end framework to significantly improve the timeliness and\\naccuracy of global earthquake-induced human loss forecasting using\\nmulti-lingual, crowdsourced social media. Our framework integrates (1) a\\nhierarchical casualty extraction model built upon large language models, prompt\\ndesign, and few-shot learning to retrieve quantitative human loss claims from\\nsocial media, (2) a physical constraint-aware, dynamic-truth discovery model\\nthat discovers the truthful human loss from massive noisy and potentially\\nconflicting human loss claims, and (3) a Bayesian updating loss projection\\nmodel that dynamically updates the final loss estimation using discovered\\ntruths. We test the framework in real-time on a series of global earthquake\\nevents in 2021 and 2022 and show that our framework streamlines casualty data\\nretrieval, achieving speed and accuracy comparable to manual methods by USGS.\\n\",\n",
       " 'url': 'http://arxiv.org/abs/2312.03755',\n",
       " 'authors': ['Chenguang Wang, Davis Engler, Xuechun Li, James Hou, David J. Wald, Kishor Jaiswal, Susu Xu']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21b4d0d8-c223-43c4-a41e-543b214ce159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(list_of_dicts):\n",
    "    merged = {}\n",
    "    for d in list_of_dicts:\n",
    "        merged.update(d)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "646574c1-e652-49f3-b0f2-5ad398076d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {'a': 1, 'b': 2}\n",
    "dict2 = {'b': 3, 'c': 4}\n",
    "dict3 = {'c': 5, 'd': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b655159-776c-45ad-9f32-563808a863c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 3, 'c': 5, 'd': 6}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_dicts([dict1, dict2, dict3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d66ee846-646d-432e-b7e7-0ac19b969cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c48a92bf-2849-4e6e-bf79-9167bfa69160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b99b7cb-a5f2-4300-b605-b9f94698e7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'http://arxiv.org/abs/2312.04275',\n",
       " 'title': 'Estimating Countries with Similar Maternal Mortality Rate using Cluster Analysis and Pairing Countries with Identical MMR. (arXiv:2312.04275v1 [cs.LG])',\n",
       " 'abstract': \"In the evolving world, we require more additionally the young era to flourish\\nand evolve into developed land. Most of the population all around the world are\\nunaware of the complications involved in the routine they follow while they are\\npregnant and how hospital facilities affect maternal health. Maternal Mortality\\nis the death of a pregnant woman due to intricacies correlated to pregnancy,\\nunderlying circumstances exacerbated by the pregnancy or management of these\\nsituations. It is crucial to consider the Maternal Mortality Rate (MMR) in\\ndiverse locations and determine which human routines and hospital facilities\\ndiminish the Maternal Mortality Rate (MMR). This research aims to examine and\\ndiscover the countries which are keeping more lavish threats of MMR and\\ncountries alike in MMR encountered. Data is examined and collected for various\\ncountries, data consists of the earlier years' observation. From the\\nperspective of Machine Learning, Unsupervised Machine Learning is implemented\\nto perform Cluster Analysis. Therefore the pairs of countries with similar MMR\\nas well as the extreme opposite pair concerning the MMR are found.\\n\",\n",
       " 'url': 'http://arxiv.org/abs/2312.04275',\n",
       " 'authors': ['S. Nandini, Sanjjushri Varshini R']}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[list(data.keys())[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76867810-293d-4b65-92c0-be35ff0113e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"../data/2023-12-08.json.gz\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ae6b57a-e267-4356-a669-5dbc5573e024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c909445f-e21d-427f-9c1d-0d29e95df509",
   "metadata": {},
   "outputs": [],
   "source": [
    "    user_message = \"\"\"\n",
    "        Please read the following paper title and abstract:\n",
    "        --------------\n",
    "        Title: {title}\n",
    "        Abstract: {abstract}\n",
    "        --------------\n",
    "        Based on the title and abstract, please decide if the paper pertains to one or multiple topics below:\n",
    "        --------------\n",
    "        {topics}\n",
    "        --------------\n",
    "        If the paper is VERY relevant to a topic, provide a short explanation of why. If the the paper is not relevant to any of the topics, reply False and leave the reason empty. The output should be in JSON format and follow the following schema:\n",
    "        --------------\n",
    "        ```json\n",
    "        {{\n",
    "            'topic 1': {{\n",
    "                'relevance': 0,\n",
    "                'reason': ''\n",
    "            }},\n",
    "            'topic 2': {{\n",
    "                'relevance': 0.9,\n",
    "                'reason': 'The paper ....'\n",
    "            }}\n",
    "        }}\n",
    "         ```\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c3ac945d-bd90-4cb9-8f8d-a45fb47d40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"../data/2023-12-08.json.gz\") as f:\n",
    "    merged_paper_list = json.loads(f.read().decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c3300d8-dd7d-44ba-974e-f24e18361efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame.from_dict(merged_paper_list.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c6e067ff-1e04-4212-8c7b-b5476fc13d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = list(merged_paper_list.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f35e98-2519-407c-8b1c-4858329caab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f6c3ebb3-794e-4b40-832a-76a178997ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Please read the following paper title and abstract:\n",
      "    --------------\n",
      "    Title: Conceptual Engineering Using Large Language Models. (arXiv:2312.03749v1 [cs.CL])\n",
      "    Abstract: We describe a method, based on Jennifer Nado's definition of classification\n",
      "procedures as targets of conceptual engineering, that implements such\n",
      "procedures using a large language model. We then apply this method using data\n",
      "from the Wikidata knowledge graph to evaluate concept definitions from two\n",
      "paradigmatic conceptual engineering projects: the International Astronomical\n",
      "Union's redefinition of PLANET and Haslanger's ameliorative analysis of WOMAN.\n",
      "We discuss implications of this work for the theory and practice of conceptual\n",
      "engineering. The code and data can be found on GitHub.\n",
      "\n",
      "    --------------\n",
      "    Based on the title and abstract, please decide if the paper pertains to one or multiple topics below:\n",
      "    --------------\n",
      "    ['Review of existing research', 'Security of AI and langauge models']\n",
      "    --------------\n",
      "    If the paper is VERY relevant to a topic, provide a short explanation of why. If the the paper is not relevant to any of the topics, reply False and leave the reason empty. The output should be in JSON format and follow the following schema:\n",
      "    --------------\n",
      "    ```json\n",
      "    {\n",
      "        'topic 1': {\n",
      "            'relevance': 0,\n",
      "            'reason': ''\n",
      "        },\n",
      "        'topic 2': {\n",
      "            'relevance': 0.9,\n",
      "            'reason': 'The paper ....'\n",
      "        }\n",
      "    }\n",
      "     ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(user_message.format(\n",
    "    title=paper['title'],\n",
    "    abstract=paper['abstract'],\n",
    "    topics=config['topics']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ee6ea37e-2af8-4139-8013-3c16cb138546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Review of existing research', 'Security of AI and langauge models']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['topics']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65068cdb-aba2-4ef0-8cfd-f8529147e42d",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "812b0635-66b4-4efe-afd1-9e236810bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "juedement_list = []\n",
    "with open(\"../data/2023-12-08.resp.json\") as f:\n",
    "    for line in f:\n",
    "        paper = json.loads(line)\n",
    "        juedement_list.append(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b6ecef7c-6244-47fe-99d0-70f8617c5be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(juedement_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8115835a-70e3-4a0f-90ce-64e3ebac0567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'http://arxiv.org/abs/2312.03749',\n",
       " 'judgement': {'Security of AI and language models': {'relevance': 0,\n",
       "   'reason': ''},\n",
       "  'Applications of AI and language models in social science research': {'relevance': 0.8,\n",
       "   'reason': 'The paper discusses the application of large language models in evaluating concept definitions from social science projects.'},\n",
       "  'Using AI to simulate humans in various contexts': {'relevance': 0.2,\n",
       "   'reason': ''},\n",
       "  'Methods to increase the factuality of language model response': {'relevance': 0.1,\n",
       "   'reason': ''},\n",
       "  'AI and language models for generating misinformation or fact-checking': {'relevance': 0.1,\n",
       "   'reason': ''}}}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "juedement_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "884e0136-ffb1-48f1-a01a-d01d782057de",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_worth_reading = []\n",
    "for judgement in juedement_list:\n",
    "    score_reason = []\n",
    "    for topic, value in judgement.items():\n",
    "        if topic == \"id\":\n",
    "            continue\n",
    "        if value['relevance'] > 0.8:\n",
    "            score_reason.append(\n",
    "                f\"<{value['relevance']}> - <{topic}>: {value['reason']}\"\n",
    "            )\n",
    "    if score_reason:\n",
    "        paper = {\n",
    "            \"id\": judgement['id'],\n",
    "            \"reason\": \" || \".join(score_reason)\n",
    "        }\n",
    "        paper_worth_reading.append(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8fdbb507-9971-43cc-a30f-d305b3eeee66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Security of AI and language models', 'Applications of AI and language models in social science research', 'Using AI to simulate humans in various contexts', 'Methods to ground the response of language models', 'AI and language models for generating misinformation or fact-checking', 'id'])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "juedement_list[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f380b9ca-0985-4879-a61f-905af1f2827d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper_worth_reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9e3ad010-327a-4509-9bc2-e4386a61ae7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper_worth_reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b62ac7d0-cdb1-4118-a9d3-24ac86f21058",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_worth_reading_df = pd.DataFrame.from_dict(paper_worth_reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f5904ffe-7246-428e-99e0-4a576861bb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://arxiv.org/abs/2312.03755</td>\n",
       "      <td>&lt;0.9&gt; - &lt;Applications of AI and language model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://arxiv.org/abs/2312.03901</td>\n",
       "      <td>&lt;0.9&gt; - &lt;Applications of AI and language model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://arxiv.org/abs/2312.03936</td>\n",
       "      <td>&lt;0.9&gt; - &lt;AI and language models for generating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://arxiv.org/abs/2303.16343</td>\n",
       "      <td>&lt;1&gt; - &lt;Applications of AI and language models ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://arxiv.org/abs/2309.08967</td>\n",
       "      <td>&lt;0.9&gt; - &lt;Applications of AI and language model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://arxiv.org/abs/2312.03707</td>\n",
       "      <td>&lt;0.9&gt; - &lt;Methods to ground the response of lan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  \\\n",
       "0  http://arxiv.org/abs/2312.03755   \n",
       "1  http://arxiv.org/abs/2312.03901   \n",
       "2  http://arxiv.org/abs/2312.03936   \n",
       "3  http://arxiv.org/abs/2303.16343   \n",
       "4  http://arxiv.org/abs/2309.08967   \n",
       "5  http://arxiv.org/abs/2312.03707   \n",
       "\n",
       "                                              reason  \n",
       "0  <0.9> - <Applications of AI and language model...  \n",
       "1  <0.9> - <Applications of AI and language model...  \n",
       "2  <0.9> - <AI and language models for generating...  \n",
       "3  <1> - <Applications of AI and language models ...  \n",
       "4  <0.9> - <Applications of AI and language model...  \n",
       "5  <0.9> - <Methods to ground the response of lan...  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_worth_reading_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ad4a6d-c0c3-4063-9a5a-ea402f6d625a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv",
   "language": "python",
   "name": "arxiv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
